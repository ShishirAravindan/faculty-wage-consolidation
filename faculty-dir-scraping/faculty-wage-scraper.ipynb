{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faculty-Wage Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Dict, Optional\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_name(full_name: str) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Split a full name into first name and last name.\n",
    "    \n",
    "    :param full_name: The full name string\n",
    "    :return: A tuple containing (first_name, last_name)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove suffixes and additional info\n",
    "    clean_name = re.sub(r\",?\\s*(Ph\\.D\\.|M\\.D\\.|J\\.D\\.|MBA|DDS|MS|BA)\\.?$\", \"\", full_name.strip())\n",
    "    clean_name = re.sub(r\"\\s*\\(.*?\\)\\s*$\", \"\", clean_name)  # Remove any text in parentheses\n",
    "    \n",
    "    # Handle special cases where names might not have a last name\n",
    "    if '-' in clean_name:  # Handle names with\n",
    "        clean_name = clean_name.split('-')[0].strip()\n",
    "    if '—' in clean_name:  # Handle names with\n",
    "        clean_name = clean_name.split('—')[0].strip()\n",
    "    \n",
    "    parts = clean_name.split()\n",
    "    \n",
    "    if len(parts) == 0:\n",
    "        return \"\", \"\"\n",
    "    if len(parts) == 1:\n",
    "        return parts[0], \"\"\n",
    "    else:\n",
    "        return ' '.join(parts[:-1]).strip(), parts[-1].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faculty_information_from_page(base_url: str, \n",
    "                                    faculty_selector: str, \n",
    "                                    name_selector: str, \n",
    "                                    rank_selector: str,\n",
    "                                    aggregate_field: str,\n",
    "                                    department: str,) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Scrape faculty directory data from a given URL, handling pagination if needed.\n",
    "    \n",
    "    :param base_url: The base URL of the faculty directory page\n",
    "    :param faculty_selector: CSS selector for each faculty member's container\n",
    "    :param name_selector: CSS selector for the faculty member's name within their container\n",
    "    :param rank_selector: CSS selector for the faculty member's rank within their container\n",
    "    :param next_page_selector: CSS selector for the \"Next Page\" link (if paginated)\n",
    "    :param max_pages: Maximum number of pages to scrape (default: 1)\n",
    "    :return: List of dictionaries containing faculty information\n",
    "    \"\"\"\n",
    "    faculty_data = []\n",
    "\n",
    "    response = requests.get(base_url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    faculty_members = soup.select(faculty_selector)\n",
    "    print(f\"Found {len(faculty_members)} members\")\n",
    "\n",
    "    for member in faculty_members:\n",
    "            name_element = member.select_one(name_selector)\n",
    "            full_name = name_element.text.strip() if name_element else ''\n",
    "            first_name, last_name = _split_name(full_name)\n",
    "            \n",
    "            rank_element = member.select_one(rank_selector)\n",
    "            rank = rank_element.text.strip() if rank_element else ''\n",
    "            \n",
    "            faculty_data.append({\n",
    "                'firstName': first_name,\n",
    "                'lastName': last_name,\n",
    "                'rank': rank,\n",
    "                'aggregateField': aggregate_field,\n",
    "                'departmentInfo': department\n",
    "            })\n",
    "\n",
    "    return faculty_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(data: List[Dict[str, str]], filename: str):\n",
    "    \"\"\"\n",
    "    Write the faculty data to a CSV file.\n",
    "    \"\"\"\n",
    "    with open(f\"output/{filename}\", 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['firstName', 'lastName', 'rank', 'aggregateField', 'departmentInfo']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for faculty in data:\n",
    "            writer.writerow(faculty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_url': 'https://pharmacy.uiowa.edu/people/', 'page_count': 10, 'aggregate_field': 'Health', 'department_info': 'Pharmacy', 'faculty_selector': '.flex .flex-col .space-y-6', 'name_selector': 'h2.text-[24px].font-bold.font-serif a', 'rank_selector': 'h3.text-[20.8px].font-serif.font-medium.text-ui-gray-cool', 'outfileName': 'HEAL_pharmacy.csv'}\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME = \"pharmacy\"\n",
    "with open(f\"scraper-configs/{FILE_NAME}.json\", 'r') as f:\n",
    "    CONFIG = json.load(f)\n",
    "print(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 members\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for page in range(CONFIG[\"page_count\"]):\n",
    "    url = f\"{CONFIG['base_url']}/?page={page}\"\n",
    "    faculty_data = get_faculty_information_from_page(url, CONFIG[\"faculty_selector\"], \n",
    "                                                     CONFIG[\"name_selector\"], CONFIG[\"rank_selector\"],\n",
    "                                                     CONFIG[\"aggregate_field\"], CONFIG[\"department_info\"])\n",
    "    print(faculty_data)\n",
    "    break\n",
    "    write_to_csv(faculty_data, CONFIG[\"outfileName\"])\n",
    "    print(f\"Scraping finished for page {page}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-off patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biostats_faculty_info(url):\n",
    "    data = []\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows[1:]:\n",
    "        name = row.find('td').get_text(strip=True)\n",
    "        first_name, last_name = _split_name(name)\n",
    "        \n",
    "        title = row.find_all('td')[1].get_text(\" \", strip=True)\n",
    "        data.append({\n",
    "            'firstName': first_name, \n",
    "            'lastName': last_name, \n",
    "            'aggregateField': \"Life Sciences\",\n",
    "            'departmentInfo': \"Biostatistics\",\n",
    "            'rank': title})\n",
    "    return data\n",
    "\n",
    "URL = \"https://www.public-health.uiowa.edu/biostatistics-faculty-list/\"\n",
    "data = get_biostats_faculty_info(URL)\n",
    "write_to_csv(data, 'LISC_biostatistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eric Vazquez\n",
      "Tara Bynum\n",
      "Tina Tootle\n",
      "Julie Stark —staff\n",
      "Margaret Beck\n",
      "Laurent Jay\n",
      "Jeremy Swanston Studio Art DGS\n",
      "Robert Bork\n",
      "Ernesto Fuentes\n",
      "Rosemary Stratton —staff\n",
      "Edward Sander\n",
      "Joshua Lobb —staff\n",
      "Prahbat Goswami\n",
      "Jacob Oleson\n",
      "Terry Kirk —staff\n",
      "Julia Leonard\n",
      "Renea Jay —staff\n",
      "Sam Burer\n",
      "Adam Dupuy\n",
      "Tina Tootle\n",
      "Alec Scranton\n",
      "Sara Hartman —staff\n",
      "Scott Shaw\n",
      "Emily Mozena\n",
      "Paula Amad\n",
      "Corey Markfort\n",
      "Kim Lebeck —staff\n",
      "Celsiana Warwick\n",
      "Anu Subramanian - Speech & Language Disorders\n",
      "Kelly Schmidt-Clay - Audiology\n",
      "Joy Hayes\n",
      "Paul Gilbert\n",
      "Torrie Malichky —staff\n",
      "Steve Goddard\n",
      "Laura Gallo\n",
      "Jennifer Kayle\n",
      "John Warren\n",
      "Jeffrey Banas\n",
      "Anil Kumar\n",
      "Kate Broton\n",
      "Hans Johnson\n",
      "Jennifer Buckley\n",
      "Ryan Carnahan\n",
      "Ashish Tiwari\n",
      "Andrean Burnett\n",
      "Laura Hefley —staff\n",
      "Anny Curtius\n",
      "Lori Wallrath\n",
      "Rob DuBay —staff\n",
      "Heather Sander\n",
      "Bradley Cramer\n",
      "Kara Whitaker\n",
      "Kanika Arora - PHD\n",
      "Kenneth Anderson - eMHA\n",
      "Kristin Wilson - MHA\n",
      "Tom Arne Midtr ø d\n",
      "Jong Sung Kim\n",
      "Kevin Legge\n",
      "Robert DuBay —staff\n",
      "Xuan Song\n",
      "Juan Pablo Hourcade\n",
      "Jan Fassler\n",
      "Marlys Boote —staff\n",
      "Thomas Oates\n",
      "Jennifer Burek-Pierce\n",
      "Christine Shea\n",
      "Chad Van Iddekinge\n",
      "Andrea Luangrath\n",
      "Xiaoyi Zhang\n",
      "Jia Lu\n",
      "Craig Ellermeier\n",
      "Cynthia Hernandez —staff\n",
      "Matthew Potthoff\n",
      "Maggie Grell-Davis\n",
      "Mark Stamnes\n",
      "Carrie Stasch —staff\n",
      "David Puderbaugh\n",
      "Michael E. Dailey Assoc Dir\n",
      "Dan Tranel\n",
      "Maggie Grell-Davis\n",
      "Dan Crawford - DNP\n",
      "Patrick O'Shaughnessy\n",
      "Brianne Schwarz —staff\n",
      "Sandra Guzman Co-director\n",
      "Jeffrey Banas\n",
      "Jeffrey Banas\n",
      "Jeffrey Banas\n",
      "Vladimir Badovinac\n",
      "Frederick Quelle\n",
      "Rory Fisher\n",
      "Lisa Ringen —staff\n",
      "David Roman\n",
      "Katarina Perovic\n",
      "Darren Casey\n",
      "Richard Shields\n",
      "Allison Jaynes\n",
      "Phuong Nguyen\n",
      "Caroline Tolbert\n",
      "Robert Ankenmann\n",
      "Ryan Lalumiere\n",
      "Lexie Just —staff\n",
      "Morten Schlutter\n",
      "Megan Knight No grad program\n",
      "Justin Cosner No grad program\n",
      "Stephen Cummings - MSW\n",
      "Megan Gilster - PHD\n",
      "Stephanie Dipietro\n",
      "Christine Shea\n",
      "Packy Moran\n",
      "Boxiang Wang\n",
      "David Cwiertny\n",
      "Derek Rodgers\n",
      "Daniel Fine\n",
      "Patricia Winokur\n",
      "Lan S. (Samantha) Chang\n"
     ]
    }
   ],
   "source": [
    "def get_DGS_faculty_info(url):\n",
    "    data = []\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows[2:]:\n",
    "        department = row.find('td').get_text(strip=True)\n",
    "        \n",
    "        names = row.find_all('td')[1].find_all('li')\n",
    "        for name in names:\n",
    "            cleaned_name = name.get_text(\" \", strip=True)\n",
    "            first_name, last_name = _split_name(cleaned_name)\n",
    "\n",
    "            data.append({\n",
    "                'firstName': first_name, \n",
    "                'lastName': last_name,\n",
    "                'departmentInfo': department,\n",
    "                'rank': \"Director\",\n",
    "            })\n",
    "    return data\n",
    "\n",
    "URL = \"https://grad.uiowa.edu/faculty-staff/dgs-graduate-faculty/current-directors\"\n",
    "data = get_DGS_faculty_info(URL)\n",
    "write_to_csv(data, 'mixed_dgs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".finPayVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
